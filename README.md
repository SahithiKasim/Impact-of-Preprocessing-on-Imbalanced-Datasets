# Impact of Preprocessing on Imbalanced Datasets

![License](https://img.shields.io/badge/license-MIT-blue.svg)

## Overview

This project tackles the challenges of credit default prediction within imbalanced datasets. By employing various preprocessing techniques, classic (XGBoost), and neural network models implemented in both Tensorflow and JAX frameworks, the analysis aims to enhance accuracy and efficiency in credit assessments.

## Key Features

- **Imbalanced Dataset Handling:** Strategies for effective handling of imbalanced datasets.
- **Multiple Models:** Implementation of classic (XGBoost) and neural network models using TensorFlow and JAX frameworks.
- **Impact Analysis:** In-depth analysis of the impact of each preprocessing technique, including imputation methods and oversampling/undersampling trade-offs.

## Analysis Insights

The analysis brought forth several key insights:

1. **Imputation Methods Effectiveness:** Evaluation of different imputation methods revealed varying impacts on model performance, shedding light on the most effective strategies.

2. **Trade-off between Oversampling and Undersampling:** The project uncovered the delicate balance between oversampling and undersampling, providing valuable guidance on achieving optimal results.

3. **Accuracy Improvement:** The implemented strategies led to a significant accuracy improvement, elevating the model from 77% to an impressive 88%.

4. **Training Time Optimization:** The project achieved a substantial reduction in training time, enhancing efficiency from over one hour to just 33 seconds.


## Acknowledgments

- The project builds upon extensive research in predictive modeling and addresses a critical aspect of credit assessments.
- Special thanks to the open-source community for their contributions to the frameworks and libraries used in this project.

Happy modeling!
